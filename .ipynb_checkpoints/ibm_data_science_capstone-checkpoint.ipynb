{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project\n",
    "### IBM Data Science Professional Certificate\n",
    "This notebook will be mainly used for the Capstone Project of the IBM Data Science Professional Certificate on Coursera.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Scraping and Cleaning the Data\n",
    "I have used the Scrapy framework for scraping the data from the specified website https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\n",
    "\n",
    "Here is the code I've written for it:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Spider code\n",
    "import scrapy\n",
    "from ..items import NeighborhoodItem\n",
    "\n",
    "class IbmWikiSpider(scrapy.Spider):\n",
    "    name = \"ibm_wiki\"\n",
    "    start_urls = [\n",
    "        'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        tbody_tr = response.xpath('//*[contains(concat(\" \", @class, \" \"), \"wikitable\")]/tbody/tr')\n",
    "        for tr in tbody:\n",
    "            neighborhood = NeighborhoodItem()\n",
    "            borough = tr.xpath('./td[2]/a/text()').get()\n",
    "            if borough is None or(len(borough.strip()) == 0):\n",
    "                borough = tr.xpath('./td[2]/text()').get()\n",
    "            neigh = tr.xpath('./td[3]/a/text()').get()\n",
    "            if neigh is None or (len(neigh.strip()) == 0):\n",
    "                neigh = tr.xpath('./td[3]/text()').get()\n",
    "            \n",
    "            neighborhood['post_code'] = tr.xpath('./td[1]/text()').get()\n",
    "            neighborhood['borough'] = borough\n",
    "            neighborhood['neighborhood'] = neigh\n",
    "            \n",
    "            yield neighborhood\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Item code\n",
    "import scrapy\n",
    "\n",
    "class NeighborhoodItem(scrapy.Item):\n",
    "    post_code = scrapy.Field()\n",
    "    borough = scrapy.Field()\n",
    "    neighborhood = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the spider the following command needs to be executed in the console - specifying the output file name and the output file extension:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scrapy crawl ibm_wiki -o toronto_neighborhoods.csv -t csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from the .csv file into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('toronto_neighborhoods.csv')\n",
    "# Reverse column order to match the example\n",
    "df = df[['post_code', 'borough', 'neighborhood']]\n",
    "# Rename column to match the exaple code\n",
    "df.rename(columns={'post_code': 'PostalCode', 'borough': 'Borough', 'neighborhood': 'Neighborhood'}, inplace=True)\n",
    "# Remove first row\n",
    "df = df[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the required data pre-processing tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only process the cells that have an assigned borough. Ignore cells with a borough that is Not assigned.\n",
    "df = df[df.Borough != 'Not assigned']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Find Coordinates and Merge Dataframes\n",
    "\n",
    "In order to utilize the Foursquare location data, I need to get the latitude and the longitude coordinates of each neighborhood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from provided .csv file into dataframe\n",
    "df_coord = pd.read_csv('Geospatial_Coordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column to match with previous label\n",
    "df_coord.rename(columns={'Postal Code': 'PostalCode'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "df = df.merge(df_coord, on='PostalCode')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clustering Neighborhoods in Toronto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Install and load modules that are not available\n",
    "#!pip install folium requests matplotlib sklearn\n",
    "import folium # map rendering library\n",
    "import requests\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a map of Toronto with neighborhoods superimposed on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create map of Toronto using latitude and longitude values\n",
    "map_tor = folium.Map(location=[43.6532, -79.3832], zoom_start=10)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(df['Latitude'], df['Longitude'], df['Borough'], df['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='yellow',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_tor)  \n",
    "    \n",
    "map_tor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore neighborhoods and segment them using Foursquare API. I start with defining a function to get the venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'YAIGDAA3TL0QTZWMZLV0ATVHVWGUOJDSV2UDENOB2Y1GX5R3'\n",
    "CLIENT_SECRET = 'QAKJZPQRVS1PENVBXZ1PF31YJFZATFDP2QTBR2SEBIEWT3WC'\n",
    "VERSION = '20180604'\n",
    "LIMIT = '500'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that I run the function for all neighborhoods to find the nearby venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venues = getNearbyVenues(names=df['Neighborhood'], latitudes=df['Latitude'], longitudes=df['Longitude'])\n",
    "# Check the shape of the dataframe\n",
    "toronto_venues.shape\n",
    "\n",
    "\n",
    "# One Hot Encoding\n",
    "toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# Group rows by neighborhood (mean of frequency of occurrence)\n",
    "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Neighborhoods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running k-means tu cluster into 6 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of clusters\n",
    "kclusters = 6\n",
    "\n",
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# Run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n",
    "\n",
    "# Check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
